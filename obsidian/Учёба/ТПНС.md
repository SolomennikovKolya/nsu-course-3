(Теория и практика нейронных сетей)

### Полезности
- [Google meet](https://meet.google.com/bqn-vtqa-qyp)
- [Табличка по лекциям](https://docs.google.com/spreadsheets/d/1WCa9pSmM-XS3a9sGbDXDgUYXFKgSINKzeVKHvyuMFYI/edit?gid=0#gid=0)
- [Табличка по семинарам 1](https://docs.google.com/spreadsheets/d/14yCJYLOlQd8IGoXpF4U1BA3V9K750hh6dkvqLFyFMkg/edit?gid=0#gid=0)
- [Табличка по семинарам 2](https://docs.google.com/spreadsheets/d/1rN-egnV9wQpLekzAwKIx0SPXYv0-B6k5DxUkDEE0u0Q/edit?gid=0#gid=0)
- [Программа курса](https://docs.google.com/document/d/1ZPGZz4EKvNUlIRXbwcw65BgoO1bEIpYR/edit)
- [Описание практических работ](https://docs.google.com/document/d/1A-21IyDohCQkSAykN3H8avDLWJPRdXO7/edit#heading=h.gjdgxs)
- [Доп материалы](https://docs.google.com/document/d/1FBNpuNCz2kkMdNkGERenytFApZwmqoBqT1lq5HGV1B0/edit?usp=sharing)
- [Датасеты](https://drive.google.com/drive/folders/1jZ_ujOF1XfcUwP4k7jMlKu1w6joPHMsy)
- [Теория по подготовке датасетов](https://docs.google.com/presentation/d/10QrGbD6f9Qwi4u3AWNyB61Udj-7AZA0x/edit#slide=id.p1)
- [Теория по нейронным сетям](https://docs.google.com/presentation/d/1CSWqbtGfYjTPc2emRpRGP91L0Stoh_F8/edit#slide=id.p1)
- [Теория по рекуррентным нейронным сетям](https://docs.google.com/presentation/d/1COmMsNF0zk6hLKe88DVHj4yjhCAOuCJQ/edit#slide=id.p1)
- [Архитектура LeNet-5](https://docs.google.com/presentation/d/1pyy--9sXTeY5CG-I_NZjBGR3h8avZ5oM/edit#slide=id.p1)

#### Инфа
- Мой датасет: Качество вина
- Моя тема доклада: Архитектура RNN
- Kaggle - там можно брать [датасеты]()
- Colab - питончик + ML
- s.uzilov@g.nsu.ru - почта семера, куда скидывать презентации

сделать матрицу ошибок (confusion matrix)
вывод функции потерь по мере обучения (как при verbose=True)

## Лекции

### Термины
- **Зависимая переменная** - основной фактор в машинном обучении, который мы хотим предсказать или понять, называется зависимой переменной. Ее также называют целевой переменной
- **Независимая переменная** - факторы, которые влияют на зависимые переменные или которые используются для прогнозирования значений зависимых переменных, называются независимыми переменным. также называемыми предикторами
- **Выброс** - это наблюдение, которое содержит либо очень низкое, либо очень высокое значение по сравнению с другими наблюдаемыми значениями. Выброс может исказить результат, поэтому его следует избегать
- **Мультиколлинеарность** - если независимые переменные сильно коррелируют друг с другом, чем с другими переменными, то такое состояние называется мультиколлинеарностью. Его не должно быть в наборе данных, потому что это создает проблемы при ранжировании наиболее влияющей переменной
- **Недообучение** и **переобучение** - если наш алгоритм хорошо работает с обучающим набором данных, но плохо работает с тестовым набором данных, то такая проблема называется переобучением. И если наш алгоритм плохо работает даже с обучающим набором данных, то такая проблема называется недообучением

#### Независимая переменная
- *Определение*: Независимые переменные — это входные данные или признаки (features), которые используются для предсказания или объяснения зависимой переменной
- *Роль*: Они представляют собой входные параметры модели, на основе которых делаются прогнозы
- *Пример*: Если вы предсказываете цену дома (зависимая переменная), то независимыми переменными могут быть площадь дома, количество комнат, район расположения и т.д

#### Зависимая переменная
- *Определение*: Зависимая переменная — это целевая переменная (target), которую модель пытается предсказать или объяснить на основе независимых переменных
- *Роль*: Это выход модели, который зависит от входных данных (независимых переменных)
- *Пример*: В задаче предсказания цены дома зависимой переменной будет сама цена дома

### Датасет

#### Распределение датасета
![[Pasted image 20250304133304.png]]

#### Кросс-валидация
![[Pasted image 20250218132707.png]]

#### Validation set помогает
- Контролировать процесс обучения
- Настраивать гиперпараметры
- Избегать переобучения
- Сохранять объективность тестового набора для финальной оценки

### Регрессия

Задача регрессии в машинном обучении (ML) — это тип задачи, в которой цель заключается в предсказании непрерывной числовой величины на основе входных данных. В отличие от задачи классификации, где предсказывается категория или класс, в регрессии результатом является число

#### Основные компоненты задачи регрессии
1. **Входные данные (признаки)**:
    - Это независимые переменные (features), которые используются для предсказания целевой переменной. Например, в задаче предсказания цены дома признаками могут быть площадь дома, количество комнат, район и т.д.
2. **Целевая переменная**:
    - Это зависимая переменная, которую мы хотим предсказать. В задаче регрессии она всегда является числовой. Например, цена дома, температура, доход и т.д.
3. **Модель регрессии**:
    - Это математическая функция, которая связывает входные данные с целевой переменной. Модель обучается на данных, чтобы минимизировать ошибку предсказания.
4. **Функция потерь (Loss function)**:
    - Это метрика, которая измеряет, насколько предсказания модели отличаются от реальных значений. Для регрессии часто используется среднеквадратичная ошибка (MSE — Mean Squared Error) или средняя абсолютная ошибка (MAE — Mean Absolute Error).
5. **Обучение модели**:
    - Процесс настройки параметров модели для минимизации функции потерь на обучающих данных.
        
#### Примеры задач регрессии:
1. *Предсказание цены дома*:
    - Признаки: площадь, количество комнат, этаж, район
    - Целевая переменная: цена дома
2. *Прогнозирование температуры*:
    - Признаки: время года, влажность, давление
    - Целевая переменная: температура
3. *Оценка времени доставки*:
    - Признаки: расстояние, тип доставки, загруженность дорог
    - Целевая переменная: время доставки

#### Популярные алгоритмы регрессии
1. **Линейная регрессия**:
    - Простейшая модель, которая предполагает линейную зависимость между признаками и целевой переменной
2. **Полиномиальная регрессия**:
    - Расширение линейной регрессии, где зависимость моделируется полиномом
3. **Метод опорных векторов (SVR — Support Vector Regression)**:
    - Используется для нелинейных данных
4. **Регрессия на основе деревьев**:
    - Например, Decision Tree Regression, Random Forest Regression, Gradient Boosting Regression (XGBoost, LightGBM, CatBoost)
5. **Нейронные сети**:
    - Глубокие нейронные сети могут использоваться для сложных задач регрессии

#### Оценка качества модели
##### Сравнение метрик
![[Pasted image 20250225140210.png]]

### Классификация

**Классификация** — это задача, которая заключается в отнесении объектов (например, данных) к одному из заранее определённых классов на основе их признаков. Это одна из основных задач в supervised learning (обучении с учителем), где модель обучается на размеченных данных (с известными метками классов), а затем используется для предсказания классов новых объектов

#### Основные подходы к классификации:
1. *Логистическая регрессия* — несмотря на название, используется для бинарной классификации
2. *Метод k-ближайших соседей (k-Nearest Neighbors, k-NN)* — ленивый алгоритм, который классифицирует объект на основе классов его ближайших соседей
3. *Деревья решений* — алгоритм, который строит иерархическую структуру решений на основе признаков
4. *Случайный лес (Random Forest)* — ансамбль деревьев решений, который улучшает точность и устойчивость модели
5. *Метод опорных векторов (Support Vector Machines, SVM)* — ищет гиперплоскость, которая наилучшим образом разделяет классы
6. *Нейронные сети* — мощный инструмент для сложных задач классификации, особенно в глубоком обучении

#### Ленивое обучение (Lazy Learning)

Ленивые алгоритмы не строят явную модель во время обучения. Вместо этого они откладывают всю обработку до момента, когда поступает новый объект для классификации. Примером такого подхода является метод k-ближайших соседей (k-NN)

- **Как работает k-NN**:
    - На этапе обучения алгоритм просто запоминает все данные
    - На этапе предсказания для нового объекта вычисляются расстояния до всех объектов в обучающей выборке
    - Выбираются k ближайших объектов, и класс нового объекта определяется на основе классов этих соседей (например, путём голосования)
- **Преимущества**:
    - Простота реализации
    - Нет необходимости строить сложную модель
    - Легко адаптируется к новым данным
- **Недостатки**:
    - Медленное предсказание, так как нужно вычислять расстояния до всех объектов
    - Чувствительность к шуму и выбросам
    - Требует много памяти для хранения всей обучающей выборки

#### Жадное обучение (Eager Learning)

Жадные алгоритмы строят явную модель на этапе обучения, которая затем используется для предсказания. Примеры: деревья решений, логистическая регрессия, SVM, нейронные сети

- **Как работает жадное обучение**:
    - На этапе обучения алгоритм анализирует данные и строит модель (например, дерево решений или гиперплоскость в SVM)
    - На этапе предсказания модель применяется к новым данным для определения их класса
- **Преимущества**:
    - Быстрое предсказание, так как модель уже построена
    - Меньше требований к памяти, так как хранится только модель, а не все данные
    - Лучше работает с большими объёмами данных
- **Недостатки**:
    - Модель может быть сложной для интерпретации (например, глубокие нейронные сети)
    - Требуется время и ресурсы для построения модели
    - Модель может быть чувствительна к изменениям в данных

#### Классификация на линейные и нелинейные модели

**Линейные модели** предполагают, что зависимость между признаками и целевой переменной можно описать линейной комбинацией признаков. Такие модели часто интерпретируемы и просты в реализации, но они могут быть ограничены в задачах, где зависимости сложные и нелинейные

Примеры:
1. Линейная регрессия
2. Логистическая регрессия
3. Метод опорных векторов (SVM) с линейным ядром

**Нелинейные модели** способны учитывать сложные зависимости между признаками и целевой переменной. Они более гибкие и мощные, но часто требуют больше вычислительных ресурсов и могут быть менее интерпретируемыми

Примеры
1. Деревья решений
2. Случайный лес (Random Forest)
3. Метод опорных векторов (SVM) с нелинейным ядром
4. Нейронные сети
5. Метод k-ближайших соседей (k-NN)

#### Оценка модели классификации

Как только наша модель будет завершена, необходимо оценить ее производительность; либо это классификационная, либо регрессионная модель.
Итак, для оценки модели классификации у нас есть следующие способы:

1. Логарифм потерь или кросс-энтропийная потеря (log loss)
2. Матрица путаницы
3. Кривая АИС-ВОС (кривая рабочих характеристик получателя)

#### Логистическая регрессия

**Логистическая регрессия** — это один из самых популярных алгоритмов машинного обучения, используемый для задач *бинарной классификации* (когда целевая переменная имеет два класса, например, "да/нет", "спам/не спам", "1/0"). Несмотря на название, это именно алгоритм классификации, а не регрессии

Основная идея:
Логистическая регрессия предсказывает вероятность принадлежности объекта к одному из двух классов. Для этого она использует логистическую функцию (сигмоиду), которая преобразует линейную комбинацию признаков в значение вероятности в диапазоне от [0, 1]

Математическая основа
1. *Линейная комбинация признаков*:  
    Логистическая регрессия сначала вычисляет линейную комбинацию входных признаков:
    z=w0+w1x1+w2x2+⋯+wnxn​, где:
    - zz — линейная комбинация
    - w0,w1,…,wn​ — веса (параметры модели)
    - x1,x2,…,xn​ — признаки объекта
2. *Логистическая функция (сигмоида)*:  
    Затем линейная комбинация z преобразуется с помощью логистической функции. Сигмоида "сжимает" значение zz в диапазон от 0 до 1, что интерпретируется как вероятность
3. *Принятие решения*:
    - Если p(y=1)≥0.5, объект классифицируется как класс 1
    - Если p(y=1)<0.5, объект классифицируется как класс 0

Обучение модели:
Логистическая регрессия обучается путём нахождения оптимальных весов w0,w1,…,wnw0​,w1​,…,wn​, которые минимизируют функцию потерь (обычно логистическую потерю или перекрёстную энтропию)

#### Оценка качества модели

Полнота (Recall) и точность (Precision) — это две важные метрики для оценки качества моделей классификации, особенно в задачах, где классы не сбалансированы (например, когда один класс встречается значительно реже другого). Эти метрики помогают понять, насколько хорошо модель справляется с предсказанием положительного класса

##### Основные понятия
1. **True Positive (TP)**:
    - Модель правильно предсказала положительный класс
    - Пример: модель предсказала, что пациент болен, и он действительно болен
2. **False Positive (FP)**:
    - Модель неправильно предсказала положительный класс
    - Пример: модель предсказала, что пациент болен, но он здоров
3. **True Negative (TN)**:
    - Модель правильно предсказала отрицательный класс
    - Пример: модель предсказала, что пациент здоров, и он действительно здоров
4. **False Negative (FN)**:
    - Модель неправильно предсказала отрицательный класс
    - Пример: модель предсказала, что пациент здоров, но он болен

**Точность (Precision)** показывает, какая доля объектов, предсказанных как положительные, действительно является положительными
- Формула: `Precision=TP/(TP+FP)`
- Отвечает на вопрос: "Насколько мы можем доверять предсказаниям модели?"
- Точность важна, когда ложные срабатывания (FP) дорого обходятся. Например, в спам-фильтрах: лучше пропустить спам (FN), чем пометить важное письмо как спам (FP)

**Полнота (Recall)** показывает, какая доля всех реальных положительных объектов была правильно предсказана моделью
- Формула: `Recall=TP/(TP+FN)`
- Отвечает на вопрос: "Сколько из всех положительных объектов мы нашли?"
- Полнота важна, когда пропуски (FN) критичны. Например, в медицине: лучше ошибиться и предсказать болезнь у здорового пациента (FP), чем пропустить болезнь (FN).

**F1-мера** — среднее гармоническое между точностью и полнотой
- Формула: `F1=2*Precission*Recall/(Precission+Recall)`
- Пригождается, так как точность и полнота часто находятся в компромиссе: увеличение одной метрики может привести к уменьшению другой

### Деревья решений

#### Энтропия

**Энтропия** — это понятие из теории информации, которое используется для измерения неопределенности или хаоса в системе. Она помогает оценить, насколько хорошо данные разделены на классы. Чем ниже энтропия, тем более "чистым" (однородным) является набор данных

Для набора данных с C классами (каждый элемент данных принадлежит одному из классов) энтропия H(S) вычисляется по формуле:
![[Pasted image 20250311133458.png]]
- pi​ — вероятность (доля) объектов класса i в наборе данных S

Логический смысл:
- Логарифм используется для измерения информации. Чем меньше вероятность события (pi​), тем больше информации оно несет (−log⁡2(pi))
- Минимальное значение (0) достигается, когда все объекты принадлежат одному классу (нет неопределенности)
- Максимальное значение достигается, когда данные равномерно распределены между классами

#### Information Gain

**Information Gain (Информационный выигрыш)** — это ключевая концепция в построении деревьев решений, которая используется для выбора наилучшего признака для разделения данных. Информационный выигрыш измеряет, насколько уменьшается неопределенность (энтропия) в данных после разделения по определенному признаку. Чем больше информационный выигрыш, тем лучше признак подходит для разделения

Информационный выигрыш IG(S,A) для набора данных S и признака A вычисляется по формуле:
![[Pasted image 20250311141154.png]]
- H(S) — энтропия исходного набора данных S
- Values(A) — множество уникальных значений признака A
- Sv​ — подмножество данных, где признак A принимает значение v
- ∣Sv∣ — количество объектов в подмножестве Sv
- ∣S∣ — общее количество объектов в наборе данных S
- H(Sv) — энтропия подмножества Sv

Замечания:
- Чем больше разница между начальной энтропией и средневзвешенной энтропией после разделения, тем больше информации мы получили, разделив данные по признаку A
- Склонен к перекосу в сторону признаков с большим количеством значений

#### Gain Ratio

**Gain Ratio (Коэффициент усиления)** — это улучшенная версия Information Gain. Он решает проблему перекоса в сторону признаков с большим количеством уникальных значений (например, идентификаторов), которые могут искусственно увеличивать информационный выигрыш, даже если они не несут полезной информации

Gain Ratio GR(S,A) для набора данных S и признака A вычисляется по формуле:
![[Pasted image 20250311153045.png]]
- IG(S,A) — информационный выигрыш для признака A
- Split Information(S,A) — мера "разделения" данных по признаку A, которая вычисляется как энтропия распределения значений признака A

Формула для Split Information(S,A):
![[Pasted image 20250311153240.png]]
- Values(A) — множество уникальных значений признака A
- Sv — подмножество данных, где признак A принимает значение v
- ∣Sv∣ — количество объектов в подмножестве Sv
- ∣S∣ — общее количество объектов в наборе данных S

Свойства Gain Ratio:
1. Нормализация: Gain Ratio нормализует информационный выигрыш, чтобы учесть сложность разделения данных по признаку
2. Устранение перекоса: Gain Ratio предотвращает выбор признаков с большим количеством уникальных значений, которые могут искусственно увеличивать информационный выигрыш
3. Чем больше Gain Ratio, тем лучше: Признак с максимальным Gain Ratio выбирается для разделения данных

Преимущества Gain Ratio:
- Устраняет перекос Information Gain в сторону признаков с большим количеством уникальных значений
- Более устойчив к шуму в данных

Недостатки Gain Ratio:
- Может быть менее эффективен, если Split Information(S,A)Split Information(S,A) близко к нулю (например, если признак имеет только одно значение)
- В таких случаях Gain Ratio становится неопределенным или слишком большим

#### Алгоритм C4.5

**Алгоритм C4.5** — это популярный алгоритм построения деревьев решений. Он является улучшенной версией алгоритма ID3 и широко используется в машинном обучении для задач классификации и регрессии. C4.5 поддерживает как категориальные, так и числовые признаки, а также умеет обрабатывать пропущенные данные

Основные особенности:
1. Использование критерия Gain Ratio: В отличие от ID3, который использует критерий Information Gain, C4.5 использует Gain Ratio, чтобы избежать перекоса в сторону признаков с большим количеством значений
2. Поддержка числовых признаков: C4.5 автоматически находит оптимальные точки разделения для числовых признаков
3. Обработка пропущенных данных: Алгоритм может работать с пропущенными значениями, используя взвешенное распределение
4. Упрощение дерева (pruning): C4.5 включает этап пост-обработки для упрощения дерева, что помогает избежать переобучения
5. Поддержка весов: Алгоритм учитывает веса объектов, что полезно для работы с несбалансированными данными

Основные шаги алгоритма:
1. Выбор признака для разделения:
    - Для каждого признака вычисляется Gain Ratio
    - Признак с максимальным Gain Ratio выбирается для разделения
2. Разделение данных:
    - Если признак категориальный, данные разделяются по его значениям
    - Если признак числовой, находится оптимальная точка разделения
3. Рекурсивное построение дерева:
    - Процесс повторяется для каждого подмножества данных, пока не будут выполнены условия остановки
4. Упрощение дерева (pruning):
    - Удаляются лишние узлы, чтобы избежать переобучения

### Ансамблевые методы

#### Стэкинг

**Стэкинг** (Stacking) — это мощный ансамблевый метод машинного обучения, который объединяет предсказания нескольких базовых моделей (например, решающих деревьев, линейных моделей, SVM и т.д.) с помощью *мета-модели* (или *обобщающей модели*). Основная идея стэкинга заключается в том, чтобы использовать сильные стороны разных моделей и компенсировать их слабости, что часто приводит к улучшению обобщающей способности и точности предсказаний

Основные компоненты стэкинга:
1. *Базовые модели (Level-0 модели)*:
    - Это несколько различных моделей, которые обучаются на исходных данных
    - Чем разнообразнее базовые модели, тем лучше, так как они могут улавливать разные аспекты данных
2. *Мета-модель (Level-1 модель)*:
    - Это модель, которая обучается на предсказаниях базовых моделей
    - Мета-модель "учится" комбинировать предсказания базовых моделей для получения более точного итогового предсказания
3. *Out-of-Fold предсказания*:
    - Чтобы избежать переобучения, предсказания базовых моделей для обучения мета-модели получаются с использованием кросс-валидации (out-of-fold predictions). Это означает, что каждая базовая модель обучается на части данных, а предсказания делаются для другой части, которая не использовалась при обучении

![[Pasted image 20250318125709.png]]
![[Pasted image 20250318125811.png]]

#### Бэггинг

**Бэггинг** (Bagging, Bootstrap Aggregating) используется для улучшения стабильности и точности моделей. Основная идея бэггинга заключается в том, чтобы обучить несколько одинаковых моделей на разных подвыборках исходных данных, а затем объединить их предсказания (например, через усреднение для регрессии или голосование для классификации). Это помогает уменьшить дисперсию модели и снизить риск переобучения

![[Pasted image 20250318130130.png]]
![[Pasted image 20250318130200.png]]
![[Pasted image 20250318130320.png]]

#### Случайный лес

**Случайный лес** (Random Forest) — это один из самых популярных ансамблевых методов машинного обучения, который основан на идее бэггинга и дополнительно использует случайный выбор признаков для построения каждого дерева

![[Pasted image 20250318130859.png]]

#### Бустинг

**Бустинг (Boosting)** — стрит последовательность моделей, где каждая следующая модель пытается исправить ошибки предыдущей. В отличие от бэггинга, где модели обучаются независимо, бустинг обучает модели последовательно, уделяя больше внимания объектам, которые были неправильно классифицированы на предыдущих шагах. Это позволяет улучшить качество модели, особенно в задачах с высокой сложностью

Популярные алгоритмы бустинга:
1. *AdaBoost (Adaptive Boosting)*:
    - Один из первых алгоритмов бустинга. Использует взвешенные объекты для обучения моделей и комбинирует их предсказания
2. *Gradient Boosting*:
    - Использует градиентный спуск для минимизации функции потерь. Каждая новая модель обучается на остатках (ошибках) предыдущей модели
3. *XGBoost (Extreme Gradient Boosting)*:
    - Оптимизированная версия Gradient Boosting, которая включает регуляризацию, параллельные вычисления и другие улучшения
4. *LightGBM*:
    - Эффективный алгоритм бустинга, который использует градиентный бустинг на основе деревьев и оптимизирован для работы с большими данными
5. *CatBoost*:
    - Алгоритм бустинга, разработанный для работы с категориальными признаками без предварительной обработки

![[Pasted image 20250318131358.png]]
![[Pasted image 20250318131709.png]]

### Логистическая регрессия

**Логистическая регрессия** — это один из самых популярных алгоритмов машинного обучения для задач бинарной классификации (когда целевая переменная имеет два класса, например, "да/нет" или "0/1"). Несмотря на название, логистическая регрессия используется именно для классификации, а не для регрессии. Основная идея заключается в том, чтобы предсказать вероятность принадлежности объекта к одному из классов с помощью логистической функции (сигмоиды)

Основные принципы логистической регрессии:
1. *Логистическая функция (сигмоида)*:
    - Логистическая регрессия использует сигмоидную функцию для преобразования линейной комбинации признаков в вероятность:
        ![[Pasted image 20250318133859.png]]
        - P(y=1∣X) — вероятность принадлежности объекта к классу 1
        - w0,w1,…,wn​ — веса модели
        - x1,x2,…,xn​ — признаки объекта
2. *Порог классификации*:
    - Если вероятность P(y=1∣X) больше 0.5, объект классифицируется как класс 1, иначе — как класс 0
3. *Обучение модели*:
    - Веса модели w0,w1,…,wn​ подбираются таким образом, чтобы максимизировать *функцию правдоподобия* (или минимизировать *логистическую функцию потерь*)

![[Pasted image 20250318133648.png]]

### Нейронные сети

**Нейронная сеть** — это математическая модель, вдохновлённая биологическими нейронами, которая состоит из узлов (нейронов) и связей (весов), способных обучаться на данных для решения различных задач (классификации, регрессии, генерации и др.).[Памятка по нейросетям](https://pikabu.ru/story/pamyatka_po_neyrosetyam_8277416)

#### Основные виды нейросетей
1. *Полносвязные* (Fully Connected, MLP – многослойный персептрон)
	- Каждый нейрон слоя соединён со всеми нейронами следующего слоя
	- Где применяется: Классификация, регрессия, анализ данных
2. *Свёрточные* (Convolutional Neural Networks, CNN)
	- Используют фильтры (свёртки) для автоматического выделения признаков из изображений
	- Свёртка — это математическая операция, при которой небольшая матрица (ядро, фильтр) скользит по входному изображению и вычисляет новые значения, выделяя важные признаки (границы, текстуры, формы)
	- Где применяется: Компьютерное зрение (распознавание лиц, классификация изображений)
3. *Рекуррентные* (Recurrent Neural Networks, RNN)
	- Учитывают последовательность входных данных благодаря обратным связям
	- Где применяется: Обработка текста, прогнозирование временных рядов, распознавание речи
4. *Долгая краткосрочная память (LSTM) и GRU*
	- Улучшенные RNN, решающие проблему затухающих градиентов
	- Где применяется? Машинный перевод, чат-боты, анализ временных рядов
5. *Трансформеры* (Transformers)
	- Основаны на механизме Self-Attention, лучше справляются с длинными последовательностями
	- Где применяется: GPT, BERT, ChatGPT – обработка естественного языка
6. *Генеративно-состязательные сети* (GANs)
	- Две сети (генератор и дискриминатор) соревнуются между собой, создавая реалистичные данные
	- Где применяется: Генерация изображений, Deepfake, улучшение качества изображений
7. *Автоэнкодеры* (Autoencoders)
	- Используются для сжатия и восстановления данных (кодировщик-декодировщик)
	- Где применяется: Удаление шума, уменьшение размерности, аномалия детекция
8. *Сетевые графовые модели* (GNN – Graph Neural Networks)
	- Работают с графами вместо обычных данных (узлы и связи)
	- Где применяется? Социальные сети, рекомендации, молекулярные структуры

![[Pasted image 20250325160348.png]]

### Персептрон

**Персептрон** — это один нейрон без скрытых слоев. Он может решать только задачи, где данные линейно разделимы (например, классификация "И" или "ИЛИ").
    
**Многослойным персептроном (MLP)** - нейронная сеть с 1 или более скрытым слоем. Может аппроксимировать любую непрерывную функцию (теорема Универсальной аппроксимации)


![[Pasted image 20250325131430.png]]
![[Pasted image 20250325132425.png]]
![[Pasted image 20250325132706.png]]
![[Pasted image 20250325132725.png]]

#### Метрики

##### MSE (Mean Squared Error) - Среднеквадратичная ошибка
![[Pasted image 20250408163052.png]]
- *Что показывает MSE*:  
    MSE измеряет средний квадрат разности между настоящими и предсказанными значениями. Меньшее значение MSE означает, что модель более точно предсказывает результаты
- *Основные моменты*:
    - Чем меньше MSE, тем лучше модель
    - MSE чувствительна к большим ошибкам (то есть выбросам), потому что ошибка возводится в квадрат. Это означает, что большие ошибки (отклонения) будут сильно влиять на MSE

##### R² (R-squared) - Коэффициент детерминации
![[Pasted image 20250408163615.png]]
- *Что показывает R²*:  
    R² измеряет, какая доля дисперсии (разброса) в данных объясняется моделью. Это коэффициент, который показывает, насколько хорошо модель объясняет вариацию в зависимой переменной
- *Основные моменты*:
    - R2=1 означает, что модель объясняет 100% вариации в данных, т.е. предсказания точны
    - R2=0 означает, что модель не объясняет вариацию в данных лучше, чем простая средняя линия
    - Если R2 отрицательное, это означает, что модель работает хуже, чем простое усреднение значений
    - Чем выше значение R², тем лучше модель объясняет данные

#### Типы оптимизаторов
1. `'lbfgs'` (Limited-memory Broyden–Fletcher–Goldfarb–Shanno)
	- Тип: Квазиньютоновский метод оптимизации
	- Особенности:
	    - Не использует мини-батчи — работает на всём датасете сразу
	    - Очень хорошо подходит для небольших наборов данных
	    - Быстро сходится при наличии небольшой сети
	- Плюсы: Быстро и точно на маленьких данных
	- Минусы: Не масштабируется на большие выборки
2. `'sgd'` (Stochastic Gradient Descent — стохастический градиентный спуск)
	- Тип: Классический метод обучения нейросетей
	- Особенности:
	    - Обновляет веса по одному примеру или мини-батчу
	    - Можно использовать momentum, Nesterov, learning rate schedule
	- Плюсы: Гибкий, хорошо масштабируется
	- Минусы: Требует настройки (learning rate, momentum), может сходиться медленно
3. `'adam'` (Adaptive Moment Estimation)
	- Тип: Популярный адаптивный оптимизатор
	- Особенности:
	    - Комбинирует идеи из RMSProp и momentum
	    - Адаптирует скорость обучения для каждого параметра
	    - Использует параметры `beta_1`, `beta_2`, `epsilon`
	- Плюсы: Быстро и надёжно сходится на большинстве задач
	- Минусы: Может переобучиться, если не использовать регуляризацию

### Свёрточные нейронные сети

**Свёрточные нейронные сети** (Convolutional Neural Networks, CNN) — это специализированный тип нейронных сетей, разработанный для обработки данных с пространственной структурой, таких как изображения, видео, аудиосигналы и даже тексты. Они стали стандартом в задачах компьютерного зрения, автоматического анализа медицинских снимков, обработки естественного языка (NLP) и других областях

![[Pasted image 20250401131407.png]]

#### Техники
- **Padding** — позволяет сохранить (или даже увеличить) пространственные размеры входных данных (например, ширину и высоту изображения)
- **Striding** (шаг свёртки) — это параметр, который определяет, на сколько пикселей смещается фильтр (ядро свёртки) при обработке входных данных. Он напрямую влияет на размер выходного тензора и скорость вычислений
- **Pooling** — это операция, которая уменьшает размерность данных, сохраняя ключевую информацию. Она применяется после свёрточных слоёв для снижения вычислительной сложности и повышения инвариантности к небольшим искажениям входных данных

![[Pasted image 20250401131933.png]]![[Pasted image 20250401132034.png]]

#### Базовая архитектура свёрточной сети
![[Pasted image 20250401133459.png]]
![[Pasted image 20250401133840.png]]

#### Типы слоёв
- **Свёрточный слой**:
	- Что делает: Применяет фильтры (ядра свёртки) к входным данным для извлечения локальных признаков (например, границ, текстур, цветовых паттернов)
	- Результат — карта признаков, где каждый элемент отражает наличие определённого признака в соответствующей области (количество карт признаков = количество фильтров)
- **Субдискретизирующий слой**:
	- Что делает: Уменьшает размерность данных (ширину и высоту), сохраняя наиболее важную информацию
	- Основные типы: Пулинг, Свёртка с шагом
- **Полносвязный слой**:
	- Это слой в нейронных сетях, где каждый нейрон соединён со всеми нейронами предыдущего слоя. Он используется для финального преобразования признаков перед классификацией или регрессией

#### Архитектуры свёрточных нейронных сетей
1. **LeNet-5 (1998)**
    - Одна из первых CNN
    - Использовалась для распознавания рукописных цифр (MNIST)
    - Простая структура: свёртка → пулинг → полносвязный слой
2. **AlexNet (2012)**
    - Победила на ImageNet
    - Использует ReLU, Dropout и два GPU
    - Сильный скачок в точности распознавания
3. **VGGNet (2014)**
    - VGG16 / VGG19: 16 или 19 весовых слоёв
    - Использует только 3x3 свёртки
    - Очень простая и однородная структура
4. **GoogLeNet / Inception (2014)**
    - Вводит Inception-модули (свёртки разных размеров параллельно)
    - Меньше параметров при высокой точности
    - Использует global average pooling
5. **ResNet (2015)**
    - Использует остаточные соединения (skip connections)
    - Успешно обучаются очень глубокие сети (50, 101, 152 слоёв и более)
    - Решает проблему затухающего градиента
6. **DenseNet (2016)**
    - Каждый слой получает на вход все предыдущие
    - Улучшает поток градиента и переиспользует признаки
    - Меньше параметров при высокой точности
7. **MobileNet (2017)**
    - Лёгкая и быстрая сеть для мобильных устройств
    - Использует depthwise separable convolutions
    - Отличный выбор для embedded-систем
8. **EfficientNet (2019)**
    - Архитектура найдена с помощью AutoML
    - Сбалансированно масштабирует глубину, ширину и разрешение
    - Высокая эффективность по точности и размеру
9. **RegNet (2020)**
    - Простая в настройке и масштабировании
    - Подходит для разных задач и устройств
    - Обнаружена в ходе автоматического поиска архитектур

