(Теория и практика нейронных сетей)

### Полезности
- [Google meet](https://meet.google.com/bqn-vtqa-qyp)
- [Табличка по лекциям](https://docs.google.com/spreadsheets/d/1WCa9pSmM-XS3a9sGbDXDgUYXFKgSINKzeVKHvyuMFYI/edit?gid=0#gid=0)
- [Табличка по семинарам 1](https://docs.google.com/spreadsheets/d/14yCJYLOlQd8IGoXpF4U1BA3V9K750hh6dkvqLFyFMkg/edit?gid=0#gid=0)
- [Табличка по семинарам 2](https://docs.google.com/spreadsheets/d/1rN-egnV9wQpLekzAwKIx0SPXYv0-B6k5DxUkDEE0u0Q/edit?gid=0#gid=0)
- [Программа курса](https://docs.google.com/document/d/1ZPGZz4EKvNUlIRXbwcw65BgoO1bEIpYR/edit)
- [Описание практических работ](https://docs.google.com/document/d/1A-21IyDohCQkSAykN3H8avDLWJPRdXO7/edit#heading=h.gjdgxs)
- [Доп материалы](https://docs.google.com/document/d/1FBNpuNCz2kkMdNkGERenytFApZwmqoBqT1lq5HGV1B0/edit?usp=sharing)
- [Датасеты](https://drive.google.com/drive/folders/1jZ_ujOF1XfcUwP4k7jMlKu1w6joPHMsy)
- [Теория по подготовке датасетов](https://docs.google.com/presentation/d/10QrGbD6f9Qwi4u3AWNyB61Udj-7AZA0x/edit#slide=id.p1)

#### Инфа
- Мой датасет: Качество вина
- Моя тема доклада: Архитектура RNN
- Kaggle - там можно брать датасеты
- Colab - питончик + ML
- s.uzilov@g.nsu.ru - почта семера, куда скидывать презентации

## Лекции

### Кросс-валидация
![[Pasted image 20250218132707.png]]

### Validation set помогает
- Контролировать процесс обучения
- Настраивать гиперпараметры
- Избегать переобучения
- Сохранять объективность тестового набора для финальной оценки

### Термины
- **Зависимая переменная** - основной фактор в машинном обучении, который мы хотим предсказать или понять, называется зависимой переменной. Ее также называют целевой переменной
- **Независимая переменная** - факторы, которые влияют на зависимые переменные или которые используются для прогнозирования значений зависимых переменных, называются независимыми переменным. также называемыми предикторами
- **Выброс** - это наблюдение, которое содержит либо очень низкое, либо очень высокое значение по сравнению с другими наблюдаемыми значениями. Выброс может исказить результат, поэтому его следует избегать
- **Мультиколлинеарность** - если независимые переменные сильно коррелируют друг с другом, чем с другими переменными, то такое состояние называется мультиколлинеарностью. Его не должно быть в наборе данных, потому что это создает проблемы при ранжировании наиболее влияющей переменной
- **Недообучение** и **переобучение** - если наш алгоритм хорошо работает с обучающим набором данных, но плохо работает с тестовым набором данных, то такая проблема называется переобучением. И если наш алгоритм плохо работает даже с обучающим набором данных, то такая проблема называется недообучением

#### Независимая переменная
- *Определение*: Независимые переменные — это входные данные или признаки (features), которые используются для предсказания или объяснения зависимой переменной
- *Роль*: Они представляют собой входные параметры модели, на основе которых делаются прогнозы
- *Пример*: Если вы предсказываете цену дома (зависимая переменная), то независимыми переменными могут быть площадь дома, количество комнат, район расположения и т.д

#### Зависимая переменная
- *Определение*: Зависимая переменная — это целевая переменная (target), которую модель пытается предсказать или объяснить на основе независимых переменных
- *Роль*: Это выход модели, который зависит от входных данных (независимых переменных)
- *Пример*: В задаче предсказания цены дома зависимой переменной будет сама цена дома

### Регрессия

Задача регрессии в машинном обучении (ML) — это тип задачи, в которой цель заключается в предсказании непрерывной числовой величины на основе входных данных. В отличие от задачи классификации, где предсказывается категория или класс, в регрессии результатом является число

#### Основные компоненты задачи регрессии
1. **Входные данные (признаки)**:
    - Это независимые переменные (features), которые используются для предсказания целевой переменной. Например, в задаче предсказания цены дома признаками могут быть площадь дома, количество комнат, район и т.д.
2. **Целевая переменная**:
    - Это зависимая переменная, которую мы хотим предсказать. В задаче регрессии она всегда является числовой. Например, цена дома, температура, доход и т.д.
3. **Модель регрессии**:
    - Это математическая функция, которая связывает входные данные с целевой переменной. Модель обучается на данных, чтобы минимизировать ошибку предсказания.
4. **Функция потерь (Loss function)**:
    - Это метрика, которая измеряет, насколько предсказания модели отличаются от реальных значений. Для регрессии часто используется среднеквадратичная ошибка (MSE — Mean Squared Error) или средняя абсолютная ошибка (MAE — Mean Absolute Error).
5. **Обучение модели**:
    - Процесс настройки параметров модели для минимизации функции потерь на обучающих данных.
        

#### Примеры задач регрессии:=
1. **Предсказание цены дома**:
    - Признаки: площадь, количество комнат, этаж, район
    - Целевая переменная: цена дома
2. **Прогнозирование температуры**:
    - Признаки: время года, влажность, давление
    - Целевая переменная: температура
3. **Оценка времени доставки**:
    - Признаки: расстояние, тип доставки, загруженность дорог
    - Целевая переменная: время доставки

#### Популярные алгоритмы регрессии
1. **Линейная регрессия**:
    - Простейшая модель, которая предполагает линейную зависимость между признаками и целевой переменной
2. **Полиномиальная регрессия**:
    - Расширение линейной регрессии, где зависимость моделируется полиномом
3. **Метод опорных векторов (SVR — Support Vector Regression)**:
    - Используется для нелинейных данных
4. **Регрессия на основе деревьев**:
    - Например, Decision Tree Regression, Random Forest Regression, Gradient Boosting Regression (XGBoost, LightGBM, CatBoost)
5. **Нейронные сети**:
    - Глубокие нейронные сети могут использоваться для сложных задач регрессии

#### Оценка качества модели
##### Сравнение метрик
![[Pasted image 20250225140210.png]]