(Научно-исследовательская работа)
 
## Извлечение знаний о предметных областях для создания интеллектуальных помощников

### Метаинформация
#### Инфа
- Научный руководитель: Пальчунов Дмитрий Евгеньевич
- Телефон: +7 953 767 8966
- Защита: 27-го декабря
- [Конвертация md в docx](https://products.groupdocs.app/conversion/md-to-docx#folderName=6d2abad8-1e34-4b66-9794-aaeb24a0bb6f&fileName=README.md)
- [Топовое оформление презентации](https://www.canva.com/templates/EADrOilzskc-black-and-blue-simple-technology-sales-presentation/)

#### Обязательные документы
1. Индивидуальное задание  
2. Отчет  
3. Отзыв  
4. Заявление на практику
5. Заявление на практику на следующий семестр
6. Презентация

#### План НИР
- [ ] Титульный лист
- [ ] Содержание
- [ ] Введение
	- Актуальность, новизна исследования, научные гипотезы
	- Теоретическая и практическая значимости работы
	- Цели и задачи
- [ ] Основная часть
	- В зависимости от темы исследования, в плане может указываться краткая теоретическая справка по направлению НИР, планируемые практические работы с описанием их этапов и т. д.
- [ ] Заключение
	- Итоги работы
	- Выводы
	- Рекомендации
- [ ] Список литературы
- [ ] Приложения (при необходимости)

#### Литература и интернет ресурсы
- [ИЗВЛЕЧЕНИЕ ЗНАНИЙ — ОСОБЕННОСТИ КОММУНИКАТИВНЫХ И ТЕКСТОЛОГИЧЕСКИХ МЕТОДОВ ПРИ ПРОЕКТИРОВАНИИ ИНТЕЛЛЕКТУАЛЬНЫХ ИНФОРМАЦИОННЫХ СИСТЕМ](https://elar.urfu.ru/bitstream/10995/80575/1/episteme_2017_06.pdf)
- [Онтология и семантика](https://habr.com/ru/articles/848274/)
- [Методы и средства построения онтологически управляемых систем приобретения знаний](https://cyberleninka.ru/article/n/metody-i-sredstva-postroeniya-ontologicheski-upravlyaemyh-sistem-priobreteniya-znaniy/viewer)
- [Инженерия знаний. Методы и модели](https://www.rulit.me/books/inzheneriya-znanij-metody-i-modeli-download-445605.html)
- [Первый древнейший: в чём уникальность языка программирования LISP](https://habr.com/ru/companies/sberbank/articles/655509/)
- [RAG — простое и понятное объяснение](https://habr.com/ru/articles/779526/)
- [Создание ИИ-ассистента, который отвечает на вопросы пользователей по базе знаний](https://habr.com/ru/companies/agima/articles/805113/)
- [Плейлист по ML и LLM](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- [Как работают языковые модели](https://habr.com/ru/companies/skillfactory/articles/837366/)
- [Chat GPT](https://chatgpt.com/)
- [Platform OpenAI](https://platform.openai.com/playground)

### Практика

#### Методы представления знаний

![[Pasted image 20250521233409.png]]

Данная концептуальная карта представляет собой систематизированную классификацию основных методов представления знаний. Несмотря на существование множества таких методов, карта охватывает лишь ключевые из них. Это обусловлено тем, что каждый метод разрабатывается под конкретные задачи и предметные области, а также под различную интерпретируемость — для человека или вычислительной системы. Одни методы лучше подходят для декларативных знаний, другие — для сенсомоторных или распределённых. Таким образом, разнообразие методов представления знаний отражает различие в когнитивных задачах и архитектурных подходах, что приводит к постоянному развитию новых форм.

На карте представлены базовые методы, из которых прочие либо выводятся в виде гибридов, либо представляют собой расширения, упрощения или вариации основных моделей.

Существенным фактором, определяющим структуру классификации, является наличие двух фундаментальных подходов к моделированию интеллекта: символического и нейрокибернетического. Соответственно, выделяются два класса методов представления знаний: символические методы и субсимволические методы (гибридные, нейросимволические методы в данной работе не рассматриваются, поскольку они представляют собой комбинации символических и субсимволических моделей).

##### Символические методы
Представляют знания в форме явно заданных структур — логических формул, понятий, правил, отношений и графов. Эти представления: интерпретируемы человеком, объяснимы, поддаются логическому выводу. 
- **Символическое представление знаний** (логика, правила, онтологии, фреймы) предполагает наличие **явных понятий и отношений** между ними — с чёткой семантикой, понятной человеку.
- Только **человек** может гарантированно создать осмысленные, интерпретируемые, корректные правила, потому что он **понимает контекст, цели, и значения символов**.
**Однако:**
- Существуют автоматизированные методы **извлечения символических знаний** (например, онтологий или правил) из текстов или табличных данных, например:
    - Извлечение триплетов (subject–predicate–object) из текстов
    - Алгоритмы rule mining (e.g. FOIL, CN2, RIPPER)
    - Генерация онтологий из доменных данных
- Но **качество таких извлечённых знаний зависит от предварительной разметки, грамматики, словарей и семантических моделей**, часто разработанных человеком

Символические методы подразделяются на три базовые группы:

1. **Логические модели**: Используют строго формализованные логические языки (пропозициональная логика, логика предикатов, логика описаний, модальные и неклассические логики) для представления и вывода знаний. Основаны на аксиомах и правилах вывода. Применяются в онтологиях, экспертных системах, верификации. Данные формальные методы дают возможность логического вывода для автоматического пополнения базы знаний или проверки фактов. Зачастую они служат основой для других методов представления знаний

2. **Сетевые модели**: Представляют знания в виде графов, где узлы — понятия или объекты, а рёбра — отношения. Сюда относятся: семантические сети, фреймы и скрипты, концептуальные графы, RDF-графы и OWL-онтологии, ассоциативные и когнитивные карты. Используются в онтологиях, системах обучения, моделях памяти.

3. **Продукционные модели**: Основываются на системе правил вида "если–то". Содержат: рабочую память (факты), продукционные правила, механизм вывода (прямой или обратный). Применяются в экспертных системах, диалоговых агентах, когнитивных архитектурах (ACT-R, SOAR).

##### Субсимволические методы
Представляют знания неявно — через числовые параметры, веса, связи или активации в распределённых структурах. Характеризуются: отсутствием явной логической структуры, плохой интерпретируемостью ("чёрный ящик"), высокой адаптивностью и обобщающей способностью. 
- **Субсимволические знания** — это внутренние представления, которые **не интерпретируются напрямую**, но **хорошо обобщают и кодируют смысл**.
    - Примеры: вектора слов (word embeddings), параметры нейросетей, attention-механизмы.
- Машина (нейросеть, модель) может автоматически «извлекать» такие представления из данных (текстов, изображений, сигналов) **без участия человека**.
- Эти знания мощны, но **неинтерпретируемы для человека**, их нельзя объяснить простыми понятиями или правилами.

Основные виды субсимволических моделей:

1. **Нейросетевые модели**: искусственные нейросети (MLP, CNN, LSTM, трансформеры), байесовские и спайковые нейросети.

2. **Векторные представления**: эмбеддинги слов и текстов (Word2Vec, BERT), представления графов и объектов.

3. **Энергетические модели**: сети Хопфилда, (Restricted) Болцмановские машины.

4. **Эвристические модели**: Используют приближённые правила и оценочные функции, часто вручную заданные или извлечённые из данных.

##### Гибридные методы
Современный тренд — гибридные системы
- Объединяют **символику (знание, логика)** и **субсимволику (обучение, векторные модели)**
- Пример: **neuro-symbolic reasoning**, где логические структуры строятся на основе embedding'ов или attention-механизмов



# Методы автоматического извлечения знаний из структурированных данных

### 1. Правила ассоциаций (Association Rule Mining)

- Основная задача — поиск частых шаблонов и ассоциативных правил между атрибутами.
    
- Алгоритмы: Apriori, FP-Growth, Eclat.
    
- Частный случай — поиск частых множеств (Frequent Itemsets).
    

### 2. Обнаружение последовательностей (Sequential Pattern Mining)

- Извлечение частых последовательностей элементов с учётом порядка.
    
- Обобщение правил ассоциаций для временных и упорядоченных данных.
    

### 3. Кластерный анализ (Clustering)

- Группировка объектов с похожими характеристиками.
    
- Виды:  
    3.1. Центроидные методы (K-means, K-medoids)  
    3.2. Иерархические методы (агломеративные, дивизивные)  
    3.3. Плотностные методы (DBSCAN, OPTICS)  
    3.4. Модельные методы (Gaussian Mixture Models)
    

### 4. Обучение правил (Rule Learning)

- Извлечение классификационных или регрессионных правил из данных.
    
- Методы: CN2, RIPPER, FOIL.
    
- Частный случай: извлечение ассоциативных правил с условиями.
    

### 5. Поиск закономерностей (Pattern Discovery)

- Выделение повторяющихся шаблонов, закономерностей и шаблонных структур.
    
- Включает методы:  
    5.1. Частые подграфы (Frequent Subgraph Mining)  
    5.2. Мотивы в данных  
    5.3. Аномалии и выбросы (Outlier Detection)
    

### 6. Генерация гипотез (Hypothesis Generation)

- Автоматическое формирование предположений или закономерностей.
    
- Часто используется в сочетании с ILP (Inductive Logic Programming).
    

### 7. Обучение логическим программам (Inductive Logic Programming, ILP)

- Извлечение правил и логических программ, которые объясняют данные.
    
- Обобщение обучения правил с логическим и символическим представлением.
    

### 8. Обработка и извлечение из графовых данных

- Методы выявления шаблонов и зависимостей в графах.
    
- Включает:  
    8.1. Извлечение подграфов  
    8.2. Обнаружение сообществ  
    8.3. Анализ путей и связей  
    8.4. Семантическое аннотирование графов
    

### 9. Обработка OLAP-кубов и многомерного анализа

- Извлечение закономерностей из многомерных данных.
    
- Методы агрегации, свёртки, раскрутки и анализа тенденций.
    

### 10. Методы формализации знаний из данных (Formal Concept Analysis, FCA)

- Формальная концептуальная классификация для выявления структурных отношений между объектами и атрибутами.
    

### 11. Извлечение шаблонов и шаблонных деревьев (Pattern Trees)

- Использование структурных деревьев для выявления повторяющихся шаблонов.
    

### 12. Методы индуктивного программирования и обучения с объяснением

- Извлечение правил с объяснениями, включая выявление причинно-следственных связей.


расскажи подробнее про Правила ассоциаций. Ответ дай в формате: описание метода, зачем нужен именно этот метод, какие алгоритмы используются, в каком виде извлекаются знания, частные случаи метода



Вот подробное описание метода правил ассоциаций в нужном формате:

---

### Правила ассоциаций

#### Описание метода

Правила ассоциаций — это метод извлечения знаний, направленный на обнаружение частых закономерностей и зависимостей между элементами в больших наборах данных. Он позволяет выявлять отношения вида «если A, то B», где A и B — множества элементов или событий, которые часто встречаются вместе.

Метод находит применение преимущественно в транзакционных и категориальных данных, например, для анализа покупательского поведения, выявления взаимосвязей между товарами, симптомами заболеваний и т.п.

---

#### Зачем нужен метод

- Для автоматического выявления устойчивых и значимых связей в данных без предварительной гипотезы.
    
- Помогает понять взаимозависимости между объектами и предсказать вероятностное появление одного события при наличии другого.
    
- Используется в маркетинге (перекрестные продажи), медицинских исследованиях, рекомендации товаров, анализе текстов и др.
    
- Позволяет оптимизировать ассортимент, выявлять ключевые комбинации факторов и принимать обоснованные решения.
    

---

#### Основные алгоритмы

- **Apriori** — классический алгоритм поиска частых множеств и генерации правил, использующий свойство монотонности поддержки (если множество редко, то и его супермножества тоже).
    
- **FP-Growth (Frequent Pattern Growth)** — более эффективный алгоритм, строящий структуру FP-дерева для компактного представления данных и без необходимости многократного сканирования базы.
    
- **Eclat** — алгоритм на основе пересечений списков транзакций, эффективен при очень больших и разреженных данных.
    

---

#### Вид извлекаемых знаний

Результатом являются правила ассоциаций формата:

`A ⇒ B [support, confidence]`

где

- `A` и `B` — множества элементов, не пересекающиеся друг с другом;
    
- `support` — поддержка (частота) правила, доля транзакций, содержащих и A, и B;
    
- `confidence` — достоверность, вероятность появления B при условии A.
    

Пример:  
`{Хлеб, Масло} ⇒ {Молоко} [support=0.3, confidence=0.8]`  
означает, что 30% всех транзакций содержат хлеб, масло и молоко, а если в корзине есть хлеб и масло, то с вероятностью 80% там будет молоко.

---

#### Частные случаи

- **Поиск частых множеств (Frequent Itemset Mining)** — выделение подмножеств элементов, которые встречаются вместе чаще заданного порога, без построения правил.
    
- **Правила с отрицаниями** — расширение, учитывающее отсутствие элементов.
    
- **Многомерные правила** — рассматривают связи между атрибутами из разных категорий.
    
- **Последовательные правила (Sequential Pattern Mining)** — анализируют порядок появления событий (расширение правил ассоциаций для временных данных).
    

---

Если нужно, могу привести примеры использования и псевдокод алгоритмов.




# Классификация автоматических методов извлечения знаний из структурированных данных для интеллектуальных систем

---

## 1. Методы извлечения ассоциативных правил и закономерностей

- **1.1 Частые множества (Frequent Itemset Mining)**  
    Поиск часто встречающихся комбинаций атрибутов или значений.
    
- **1.2 Правила ассоциаций (Association Rule Mining)**  
    Выделение правил вида «Если A, то B» с поддержкой и доверием (support, confidence).
    
- **1.3 Последовательные паттерны (Sequential Pattern Mining)**  
    Извлечение частых упорядоченных последовательностей.
    
- **1.4 Временные и пространственные ассоциации**  
    Расширение правил ассоциаций с учётом времени и пространственных характеристик.
    

---

## 2. Методы обучения правил и логических моделей

- **2.1 Обучение правил (Rule Learning)**  
    Автоматическое формирование интерпретируемых правил классификации/регрессии (CN2, RIPPER, FOIL).
    
- **2.2 Индуктивное логическое программирование (Inductive Logic Programming, ILP)**  
    Обучение логических правил и программ, подходящих для формализации знаний и объяснимого вывода.
    
- **2.3 Обучение с объяснениями (Explainable Rule Learning)**  
    Методы извлечения правил, обеспечивающие понятные человеку интерпретации.
    

---

## 3. Методы анализа структурированных графовых данных

- **3.1 Извлечение подграфов и шаблонов**  
    Поиск часто встречающихся подструктур в графах знаний или сетях.
    
- **3.2 Выделение сообществ и кластеров в графах**  
    Обнаружение связанных подгрупп объектов.
    
- **3.3 Семантический анализ и аннотирование графов**  
    Автоматическое обогащение графовых данных семантической информацией.
    

---

## 4. Методы формального анализа и концептуализации

- **4.1 Формальный концептуальный анализ (Formal Concept Analysis, FCA)**  
    Выявление концептов и связей между объектами и атрибутами.
    
- **4.2 Построение иерархий и онтологий**  
    Автоматическое или полуавтоматическое создание таксономий и онтологических структур из данных.
    

---

## 5. Методы кластерного анализа и сегментации

- **5.1 Центроидные методы (K-means, K-medoids)**  
    Группировка объектов на основе расстояний.
    
- **5.2 Иерархические методы (Agglomerative, Divisive)**  
    Построение древовидных структур кластеров.
    
- **5.3 Плотностные методы (DBSCAN, OPTICS)**  
    Определение кластеров на основе плотности объектов.
    
- **5.4 Алгоритмы для высокоразмерных данных и больших объемов (MiniBatch K-means, BIRCH)**
    

---

## 6. Методы извлечения шаблонов и аномалий

- **6.1 Поиск шаблонов (Pattern Mining)**  
    Обнаружение повторяющихся структур в данных.
    
- **6.2 Обнаружение аномалий (Anomaly Detection)**  
    Автоматическое выявление необычных или исключительных данных.
    
- **6.3 Выделение тенденций и изменений (Change Detection)**
    

---

## 7. Методы генерации гипотез и индуктивного вывода

- Автоматическое формирование новых предположений и выводов на основе имеющихся данных.
    
- Связаны с ILP и обучением правил.
    

---

## 8. Методы извлечения знаний из многомерных и OLAP-данных

- Анализ и агрегирование данных, представленных в виде многомерных кубов.
    
- Выделение тенденций и закономерностей в срезах данных.



### 1. Методы извлечения ассоциативных правил и закономерностей
Эти методы направлены на автоматическое выявление частых и значимых взаимосвязей между элементами данных в больших наборах структурированной информации.
#### 1.1 Частые множества (Frequent Itemset Mining)
Задача состоит в поиске таких комбинаций (множеств) атрибутов или значений, которые встречаются в данных с частотой выше заданного порога. Например, в транзакционных данных магазина частым множеством могут быть товары, которые покупаются вместе достаточно часто.
- _Пример:_ Часто вместе покупают «хлеб» и «масло».
- Это базовый этап для последующего построения ассоциативных правил.
#### 1.2 Правила ассоциаций (Association Rule Mining)
На основе частых множеств формируются правила вида «Если A, то B», которые выражают вероятность появления набора B при условии наличия набора A.
- **Поддержка (support)** — доля транзакций, содержащих и A, и B.
- **Доверие (confidence)** — условная вероятность того, что B присутствует при наличии A.
Правила с высокой поддержкой и доверием считаются сильными и полезными для принятия решений.
- _Пример:_ «Если покупают хлеб, то с вероятностью 80% покупают масло».
#### 1.3 Последовательные паттерны (Sequential Pattern Mining)
Расширяет правила ассоциаций с учётом порядка появления элементов. Извлекаются часто встречающиеся последовательности событий или элементов, где важен именно порядок.
- _Пример:_ В интернет-магазине клиенты часто сначала просматривают товар A, затем товар B, и после этого совершают покупку товара C.
#### 1.4 Временные и пространственные ассоциации
Данный метод учитывает дополнительный контекст времени или пространства при поиске закономерностей. То есть извлекаются ассоциации с учётом, например, когда (время) или где (местоположение) происходят события.
- _Пример временной ассоциации:_ Покупка сезонных товаров — купили шубу — часто покупают и зимние ботинки в течение месяца.
- _Пример пространственной ассоциации:_ В одном регионе люди чаще покупают определённый набор товаров, отличающийся от другого региона.

### 2. Методы обучения правил и логических моделей
Эти методы направлены на автоматическое извлечение правил и логических структур из структурированных данных, которые легко интерпретировать и использовать для построения интеллектуальных систем.
#### 2.1 Обучение правил (Rule Learning)
Метод основан на автоматическом построении набора правил вида «Если условие, то класс/значение», которые классифицируют объекты или предсказывают значения. Каждый правило — конъюнкция условий над атрибутами данных.
- Алгоритмы:
    - **CN2** — последовательно строит правила, отбирая условия, максимизирующие качество классификации на обучающей выборке;
    - **RIPPER** — генерирует множество правил, оптимизируя точность и обобщающую способность, при этом минимизируя переобучение;
    - **FOIL** — индуктивный алгоритм для извлечения логических правил в форме Horn-клауз (логика первого порядка) из данных.
- Результат: конечный набор правил, которые однозначно объясняют класс объекта при выполнении условий.
#### 2.2 Индуктивное логическое программирование (ILP)
ILP — метод обучения, строящий логические программы (правила в логике первого порядка) на основе положительных и отрицательных примеров и фоновых знаний.
- Формальное задание: найти теорию HHH (набор правил), такую что:
    фоновые знания∪H⊨положительные примеры\text{фоновые знания} \cup H \models \text{положительные примеры}фоновые знания∪H⊨положительные примеры
    и
    фоновые знания∪H⊭отрицательные примеры\text{фоновые знания} \cup H \not\models \text{отрицательные примеры}фоновые знания∪H⊨отрицательные примеры
- Особенность: правила могут содержать переменные, кванторы и рекурсию.
- Используется для формализации сложных знаний и построения объяснимых моделей.
#### 2.3 Обучение с объяснениями (Explainable Rule Learning)
Методы, в которых результатом является набор правил с акцентом на прозрачность:
- Правила имеют ограниченную сложность (например, небольшое число условий);
- Каждое правило снабжено метриками интерпретируемости (простота, покрытие, достоверность);
- Позволяют отслеживать причину принятия решения (трассировка вывода по правилам).
Цель — обеспечить баланс между точностью модели и её понятностью для человека, что критично для интеллектуальных систем с требованиями к объяснимости.


### 3. Методы анализа структурированных графовых данных
Методы анализа графовых структур используются для извлечения знаний из данных, естественным образом представленных в виде графов: социальных сетей, онтологий, сетей взаимосвязей и т.п. Граф состоит из множества вершин (узлов) и рёбер (связей), описывающих отношения между объектами.
#### 3.1 Извлечение подграфов и шаблонов
- Задача: найти в большом графе часто встречающиеся подграфы (подструктуры), которые могут служить шаблонами или закономерностями.
- Формально: подграф G′G'G′ является частым, если количество вхождений G′G'G′ в исходный граф GGG превышает заданный порог.
- Алгоритмы: gSpan, SUBDUE, FSG.
- Применение: выявление повторяющихся связей и структур, выявление паттернов в социальных или биологических сетях.
#### 3.2 Выделение сообществ и кластеров в графах
- Задача: разбить граф на подграфы (сообщества, кластеры), внутри которых узлы связаны плотнее, чем с внешними узлами.
- Цель — выявить естественные группы объектов, имеющих общие свойства или функции.
- Методы: алгоритмы на основе модульности (Louvain), спектральная кластеризация, алгоритмы на основе плотности (Label Propagation).
- Применение: анализ социальных групп, выявление функциональных модулей в биологических сетях.
#### 3.3 Семантический анализ и аннотирование графов
- Задача: автоматическое добавление семантической информации к элементам графа — узлам и рёбрам.
- Включает выделение сущностей, определение типов узлов, связывание с внешними онтологиями и базами знаний.
- Используются техники NLP, машинного обучения и логического вывода.
- Применение: расширение знаний в онтологиях, семантическое обогащение данных для интеллектуальных систем.

## 4. Методы формального анализа и концептуализации
Эти методы направлены на формальное выявление структурных и смысловых отношений между объектами и их свойствами с целью построения абстрактных моделей знаний.
### 4.1 Формальный концептуальный анализ (Formal Concept Analysis, FCA)
- FCA — математический метод, основанный на теории решёток, который позволяет выявлять иерархии **формальных концептов** из бинарных отношений между множествами объектов и их атрибутов.
- Формальный концепт — пара (A,B)(A, B)(A,B), где AAA — множество объектов, обладающих всеми атрибутами из BBB, и BBB — множество атрибутов, общих для всех объектов из AAA.
- Метод строит концептуальную решётку — частично упорядоченную структуру, которая отражает взаимосвязи и иерархию концептов.
- Применяется для систематизации знаний, анализа данных и построения таксономий.
### 4.2 Построение иерархий и онтологий
- Автоматическое или полуавтоматическое создание иерархических структур (таксономий) и онтологических моделей из исходных данных.
- Включает выявление классов, подклассов, отношений «является частью», ограничений и свойств.
- Используются алгоритмы кластеризации, анализа частых паттернов, логического вывода и машинного обучения.
- Результат — формальная онтология или таксономия, пригодная для последующего логического вывода и интеграции в интеллектуальные системы.