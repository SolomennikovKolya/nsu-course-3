(Научно-исследовательская работа)
 
## Извлечение знаний о предметных областях для создания интеллектуальных помощников

### Метаинформация
#### Инфа
- Научный руководитель: Пальчунов Дмитрий Евгеньевич
- Телефон: +7 953 767 8966
- Защита: 27-го декабря
- [Конвертация md в docx](https://products.groupdocs.app/conversion/md-to-docx#folderName=6d2abad8-1e34-4b66-9794-aaeb24a0bb6f&fileName=README.md)
- [Топовое оформление презентации](https://www.canva.com/templates/EADrOilzskc-black-and-blue-simple-technology-sales-presentation/)

#### Обязательные документы
1. Индивидуальное задание  
2. Отчет  
3. Отзыв  
4. Заявление на практику
5. Заявление на практику на следующий семестр
6. Презентация

#### План НИР
- [ ] Титульный лист
- [ ] Содержание
- [ ] Введение
	- Актуальность, новизна исследования, научные гипотезы
	- Теоретическая и практическая значимости работы
	- Цели и задачи
- [ ] Основная часть
	- В зависимости от темы исследования, в плане может указываться краткая теоретическая справка по направлению НИР, планируемые практические работы с описанием их этапов и т. д.
- [ ] Заключение
	- Итоги работы
	- Выводы
	- Рекомендации
- [ ] Список литературы
- [ ] Приложения (при необходимости)

#### Литература и интернет ресурсы
- [ИЗВЛЕЧЕНИЕ ЗНАНИЙ — ОСОБЕННОСТИ КОММУНИКАТИВНЫХ И ТЕКСТОЛОГИЧЕСКИХ МЕТОДОВ ПРИ ПРОЕКТИРОВАНИИ ИНТЕЛЛЕКТУАЛЬНЫХ ИНФОРМАЦИОННЫХ СИСТЕМ](https://elar.urfu.ru/bitstream/10995/80575/1/episteme_2017_06.pdf)
- [Онтология и семантика](https://habr.com/ru/articles/848274/)
- [Методы и средства построения онтологически управляемых систем приобретения знаний](https://cyberleninka.ru/article/n/metody-i-sredstva-postroeniya-ontologicheski-upravlyaemyh-sistem-priobreteniya-znaniy/viewer)
- [Инженерия знаний. Методы и модели](https://www.rulit.me/books/inzheneriya-znanij-metody-i-modeli-download-445605.html)
- [Первый древнейший: в чём уникальность языка программирования LISP](https://habr.com/ru/companies/sberbank/articles/655509/)
- [RAG — простое и понятное объяснение](https://habr.com/ru/articles/779526/)
- [Создание ИИ-ассистента, который отвечает на вопросы пользователей по базе знаний](https://habr.com/ru/companies/agima/articles/805113/)
- [Плейлист по ML и LLM](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- [Как работают языковые модели](https://habr.com/ru/companies/skillfactory/articles/837366/)
- [Chat GPT](https://chatgpt.com/)
- [Platform OpenAI](https://platform.openai.com/playground)

### Практика

#### Методы представления знаний

![[Pasted image 20250521233409.png]]

Данная концептуальная карта представляет собой систематизированную классификацию основных методов представления знаний. Несмотря на существование множества таких методов, карта охватывает лишь ключевые из них. Это обусловлено тем, что каждый метод разрабатывается под конкретные задачи и предметные области, а также под различную интерпретируемость — для человека или вычислительной системы. Одни методы лучше подходят для декларативных знаний, другие — для сенсомоторных или распределённых. Таким образом, разнообразие методов представления знаний отражает различие в когнитивных задачах и архитектурных подходах, что приводит к постоянному развитию новых форм.

На карте представлены базовые методы, из которых прочие либо выводятся в виде гибридов, либо представляют собой расширения, упрощения или вариации основных моделей.

Существенным фактором, определяющим структуру классификации, является наличие двух фундаментальных подходов к моделированию интеллекта: символического и нейрокибернетического. Соответственно, выделяются два класса методов представления знаний: символические методы и субсимволические методы (гибридные, нейросимволические методы в данной работе не рассматриваются, поскольку они представляют собой комбинации символических и субсимволических моделей).

##### Символические методы
Представляют знания в форме явно заданных структур — логических формул, понятий, правил, отношений и графов. Эти представления: интерпретируемы человеком, объяснимы, поддаются логическому выводу. 
- **Символическое представление знаний** (логика, правила, онтологии, фреймы) предполагает наличие **явных понятий и отношений** между ними — с чёткой семантикой, понятной человеку.
- Только **человек** может гарантированно создать осмысленные, интерпретируемые, корректные правила, потому что он **понимает контекст, цели, и значения символов**.
**Однако:**
- Существуют автоматизированные методы **извлечения символических знаний** (например, онтологий или правил) из текстов или табличных данных, например:
    - Извлечение триплетов (subject–predicate–object) из текстов
    - Алгоритмы rule mining (e.g. FOIL, CN2, RIPPER)
    - Генерация онтологий из доменных данных
- Но **качество таких извлечённых знаний зависит от предварительной разметки, грамматики, словарей и семантических моделей**, часто разработанных человеком

Символические методы подразделяются на три базовые группы:

1. **Логические модели**: Используют строго формализованные логические языки (пропозициональная логика, логика предикатов, логика описаний, модальные и неклассические логики) для представления и вывода знаний. Основаны на аксиомах и правилах вывода. Применяются в онтологиях, экспертных системах, верификации. Данные формальные методы дают возможность логического вывода для автоматического пополнения базы знаний или проверки фактов. Зачастую они служат основой для других методов представления знаний

2. **Сетевые модели**: Представляют знания в виде графов, где узлы — понятия или объекты, а рёбра — отношения. Сюда относятся: семантические сети, фреймы и скрипты, концептуальные графы, RDF-графы и OWL-онтологии, ассоциативные и когнитивные карты. Используются в онтологиях, системах обучения, моделях памяти.

3. **Продукционные модели**: Основываются на системе правил вида "если–то". Содержат: рабочую память (факты), продукционные правила, механизм вывода (прямой или обратный). Применяются в экспертных системах, диалоговых агентах, когнитивных архитектурах (ACT-R, SOAR).

##### Субсимволические методы
Представляют знания неявно — через числовые параметры, веса, связи или активации в распределённых структурах. Характеризуются: отсутствием явной логической структуры, плохой интерпретируемостью ("чёрный ящик"), высокой адаптивностью и обобщающей способностью. 
- **Субсимволические знания** — это внутренние представления, которые **не интерпретируются напрямую**, но **хорошо обобщают и кодируют смысл**.
    - Примеры: вектора слов (word embeddings), параметры нейросетей, attention-механизмы.
- Машина (нейросеть, модель) может автоматически «извлекать» такие представления из данных (текстов, изображений, сигналов) **без участия человека**.
- Эти знания мощны, но **неинтерпретируемы для человека**, их нельзя объяснить простыми понятиями или правилами.

Основные виды субсимволических моделей:

1. **Нейросетевые модели**: искусственные нейросети (MLP, CNN, LSTM, трансформеры), байесовские и спайковые нейросети.

2. **Векторные представления**: эмбеддинги слов и текстов (Word2Vec, BERT), представления графов и объектов.

3. **Энергетические модели**: сети Хопфилда, (Restricted) Болцмановские машины.

4. **Эвристические модели**: Используют приближённые правила и оценочные функции, часто вручную заданные или извлечённые из данных.

##### Гибридные методы
Современный тренд — гибридные системы
- Объединяют **символику (знание, логика)** и **субсимволику (обучение, векторные модели)**
- Пример: **neuro-symbolic reasoning**, где логические структуры строятся на основе embedding'ов или attention-механизмов



# Методы автоматического извлечения знаний из структурированных данных

### **Частые множества (frequent itemsets)**

- Ищутся **наборы атрибутов или значений**, которые часто встречаются вместе в данных.
    
- Например, в покупках: {хлеб, масло} встречается в 30% транзакций — это частое множество.
    
- Используется как основа для дальнейшего построения ассоциативных правил.
    

---

### 🔹 **Правила ассоциаций (association rules)**

- Формируются **условные правила** вида:  
    **Если A, то B**  
    Например: если покупают **хлеб**, то покупают и **масло**.
    
- Оцениваются метриками:
    
    - **Support (поддержка):** насколько часто A и B встречаются вместе
        
    - **Confidence (доверие):** насколько часто B следует за A
        

---

### 🔹 **Последовательные паттерны (sequential patterns)**

- Анализируются **временные или логические последовательности событий**.  
    Например:  
    Пользователь сначала смотрит «страницу A», потом «страницу B», затем «оформляет заказ».
    
- Ищутся **часто повторяющиеся последовательности** действий.
    

---

### 🔹 **Временные и пространственные ассоциации**

- Учитываются **время и/или место** событий при извлечении закономерностей.
    
- Например:
    
    - «Если покупка хлеба утром в будни — то часто покупают кофе» (временная)
        
    - «Если пользователь находится в районе X, он заказывает еду из ресторана Y» (пространственная)

### **Обучение правил**

- Автоматически **генерируются простые, человекочитаемые правила**, например:  
    **ЕСЛИ возраст > 50 И давление высокое, ТО риск = высокий**
    
- Эти правила подходят для **классификации** или **регрессии**
    
- Примеры алгоритмов:
    
    - **CN2** — жадное построение правил с использованием энтропии
        
    - **RIPPER** — эффективный метод генерации компактных наборов правил
        
    - **FOIL** — работает с логикой первого порядка, извлекая правила вида "Если A(x), то B(x)"
        

---

### 🔹 **Индуктивное логическое программирование (ILP)**

- Использует **формальную логику первого порядка** для построения правил
    
- Включает **фоновые знания** (например, определения, отношения, факты), чтобы лучше обучаться
    
- Пример правила ILP:  
    `risky(Patient) :- age(Patient, X), X > 60, has_disease(Patient, hypertension)`
    
- Особенно применимо, когда данные **структурированы** и важна **интерпретируемость**
    

---

### 🔹 **Обучение с объяснениями (Explainable Learning)**

- Основной акцент — на **понятности и прозрачности** моделей
    
- Алгоритмы обучаются так, чтобы можно было **понятно объяснить** принятие решений
    
- Часто используется в чувствительных областях: медицина, финансы, юриспруденция
    
- Может включать:
    
    - Прямое извлечение правил из сложной модели (например, из дерева решений)
        
    - Построение "простой модели" (суррогата) для объяснения сложной нейросети

### **Извлечение подграфов и шаблонов**

- Цель: найти **повторяющиеся фрагменты** (подграфы) внутри больших графов знаний.
    
- Эти подграфы представляют **типовые связи и структуры**, которые часто встречаются в данных.
    
- Пример:
    
    - В графе "человек — работает в — организация" такой шаблон может встречаться сотни раз.
        
- Используется, например, для:
    
    - Обнаружения **типовых паттернов поведения**
        
    - **Классификации узлов** по окружению
        
    - **Сокращения** объёма графа без потери смысла
        

---

### 🔹 **Семантический анализ и аннотирование графов**

- Автоматическое добавление **семантики** — смысловой информации — к элементам графа.
    
- Это может включать:
    
    - **Присвоение классов** узлам (например, узел = человек, организация и т.д.)
        
    - **Уточнение связей** с помощью онтологий (например, "работает в" → "входит в трудовые отношения")
        
    - Добавление **контекста** (времени, источника, уверенности)
        
- Цель: сделать граф **понятным и машиночитаемым**, повысить точность запросов и анализа.

### **Формальный концептуальный анализ (FCA)**

- Метод анализа табличных данных (объекты × признаки) для **выделения концептов**.
    
- **Концепт** — это пара:  
    – множество объектов,  
    – и общие для них атрибуты.
    
- Из всех таких концептов строится **концептуальная решётка** — иерархическая структура, показывающая взаимосвязи понятий.
    

**Пример:**  
В таблице:
Объекты → признаки  
A → {x, y}  
B → {x, y, z}  
C → {y, z}

→ будут найдены концепты вроде:  
{A, B} ↔ {x, y} и визуализированы в виде решётки.

### 🔹 **Построение иерархий и онтологий**

- Автоматическое создание **таксономий** (древовидных структур типа "общее → частное") и **онтологий** (связанных понятий с ролями и отношениями).
    
- Может использовать:
    
    - Частоту совместного появления понятий
        
    - Статистический анализ текста
        
    - Существующие графы знаний
        

**Пример:**  
Из текстов формируется иерархия:  
_животное → млекопитающее → хищник → волк_

- Онтологии добавляют роли:  
    _волк — охотится на → олень_

### **Методы генерации гипотез и индуктивного вывода**

- Направлены на **автоматическое построение новых знаний** из имеющихся фактов и наблюдений.
    
- Суть: по данным или примерам **выводятся общие закономерности или предположения**.
    

---

#### 🔸 Генерация гипотез:

- Система **формулирует возможные объяснения** наблюдаемых данных.
    
- Примеры:
    
    - «Если пациенты с признаком A часто выздоравливают, возможно, A способствует выздоровлению»
        
    - «Если все объекты с атрибутами X и Y относятся к классу Z, можно предположить правило: X ∧ Y ⇒ Z»
        

---

#### 🔸 Индуктивный вывод:

- **Переход от частного к общему**:
    
    - На основе набора фактов строятся **общие правила**.
        
- Примеры:
    
    - На основе наблюдений вида:
Воробей летает  
Голубь летает  
Орёл летает  

→ вывод: «Все птицы летают» (гипотеза, требующая проверки)